# -*- coding: utf-8 -*-
# tools/transcriber.py
import time
import logging
import argparse
import torch
from pathlib import Path
from opencc import OpenCC
import json
import sys
from faster_whisper.utils import get_assets_path

# --- å…¨åŸŸå¸¸æ•¸ ---
# å®šç¾©ä¸‹è¼‰é€²åº¦å›å ±çš„æœ€å°æ™‚é–“é–“éš” (ç§’)
PROGRESS_REPORT_INTERVAL = 0.5
# ç¹ç°¡è½‰æ›å™¨
CC = OpenCC('s2t')

# --- æ—¥èªŒè¨­å®š ---
# å°‡æ‰€æœ‰æ—¥èªŒå’Œé€²åº¦è¨Šæ¯å°å‘æ¨™æº–éŒ¯èª¤æµ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    stream=sys.stderr
)
log = logging.getLogger('transcriber_tool')

class Transcriber:
    def __init__(self, model_size="large-v3"):
        self.model_size = model_size
        self.model = self._load_model()
        self.last_report_time = 0

    def _load_model(self):
        """è¼‰å…¥ faster-whisper æ¨¡å‹ã€‚"""
        log.info(f"æº–å‚™è¼‰å…¥ '{self.model_size}' æ¨¡å‹...")
        device = "cuda" if torch.cuda.is_available() else "cpu"
        compute_type = "float16" if torch.cuda.is_available() else "int8"
        log.info(f"è£ç½®: {device}, è¨ˆç®—é¡å‹: {compute_type}")

        start_time = time.time()
        try:
            from faster_whisper import WhisperModel
            model = WhisperModel(self.model_size, device=device, compute_type=compute_type)
            duration = time.time() - start_time
            log.info(f"âœ… æˆåŠŸè¼‰å…¥ '{self.model_size}' æ¨¡å‹åˆ° {device.upper()}ï¼è€—æ™‚: {duration:.2f} ç§’ã€‚")
            return model
        except ImportError as e:
            log.critical(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—ï¼šç¼ºå°‘ 'faster_whisper' æˆ– 'torch' æ¨¡çµ„ã€‚è«‹ç¢ºèªç’°å¢ƒå·²æ­£ç¢ºå®‰è£ã€‚")
            raise e
        except Exception as e:
            log.critical(f"âŒ è¼‰å…¥ '{self.model_size}' æ¨¡å‹æ™‚ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤: {e}", exc_info=True)
            raise e

    def _report_progress(self, progress: float):
        """ä»¥ JSON æ ¼å¼å›å ±é€²åº¦åˆ° stdoutï¼Œä¸¦æ§åˆ¶å›å ±é »ç‡ã€‚"""
        current_time = time.time()
        if current_time - self.last_report_time >= PROGRESS_REPORT_INTERVAL:
            progress_data = {
                "type": "progress",
                "percent": round(progress, 2),
                "description": "AI æ­£åœ¨è™•ç†éŸ³è¨Š..."
            }
            # ä½¿ç”¨ print å°‡ JSON è¼¸å‡ºåˆ° stdoutï¼Œä¸¦ç¢ºä¿ç«‹å³åˆ·æ–°
            print(json.dumps(progress_data), flush=True)
            self.last_report_time = current_time

    def transcribe(self, audio_path: str, language: str = None, beam_size: int = 5) -> str:
        """åŸ·è¡ŒéŸ³è¨Šè½‰éŒ„ã€‚"""
        try:
            log.info("æ¨¡å‹è¼‰å…¥å®Œæˆï¼Œé–‹å§‹è½‰éŒ„...")

            segments, info = self.model.transcribe(audio_path, beam_size=beam_size, language=language, word_timestamps=True)

            detected_lang_msg = f"'{info.language}' (æ©Ÿç‡: {info.language_probability:.2f})"
            if language:
                log.info(f"ğŸŒ ä½¿ç”¨è€…æŒ‡å®šèªè¨€: '{language}'ï¼Œæ¨¡å‹åµæ¸¬åˆ° {detected_lang_msg}")
            else:
                log.info(f"ğŸŒ æœªæŒ‡å®šèªè¨€ï¼Œæ¨¡å‹è‡ªå‹•åµæ¸¬åˆ° {detected_lang_msg}")

            full_transcript = []
            total_duration = info.duration

            for segment in segments:
                # ç°¡è½‰ç¹
                text_simplified = segment.text
                text_traditional = CC.convert(text_simplified)

                # å»ºç«‹åŒ…å«æ™‚é–“æˆ³çš„å–®è¡Œæ–‡å­—
                start_time = time.strftime('%H:%M:%S', time.gmtime(segment.start))
                end_time = time.strftime('%H:%M:%S', time.gmtime(segment.end))
                line = f"[{start_time} --> {end_time}] {text_traditional}"
                full_transcript.append(line)

                # å›å ±é€²åº¦
                progress = (segment.end / total_duration) * 100
                self._report_progress(progress)

                # ä¹Ÿå°‡æ¯å€‹ç‰‡æ®µçš„è©³ç´°è³‡è¨Šä»¥ JSON æ ¼å¼è¼¸å‡ºåˆ° stdout
                segment_data = {
                    "type": "segment",
                    "start": round(segment.start, 2),
                    "end": round(segment.end, 2),
                    "text": text_traditional
                }
                print(json.dumps(segment_data), flush=True)

            log.info("âœ… è½‰éŒ„å®Œæˆã€‚")
            return "\n".join(full_transcript)

        except Exception as e:
            log.critical(f"âŒ è½‰éŒ„éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)
            raise e

def check_model_exists(model_size: str) -> bool:
    """æª¢æŸ¥æ¨¡å‹æ˜¯å¦å·²åœ¨æœ¬åœ°å¿«å–ã€‚"""
    try:
        # faster-whisper å°‡æ¨¡å‹å­˜åœ¨ huggingface å¿«å–ç›®éŒ„
        # æˆ‘å€‘é€éæª¢æŸ¥æ¨¡å‹ç›®éŒ„æ˜¯å¦å­˜åœ¨ä¾†åˆ¤æ–·
        assets_dir = get_assets_path()
        model_path = Path(assets_dir) / f"models--Systran--faster-whisper-{model_size}"
        return model_path.exists()
    except Exception as e:
        log.error(f"æª¢æŸ¥æ¨¡å‹ '{model_size}' æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return False

def download_model_with_progress(model_size: str):
    """ä¸‹è¼‰æ¨¡å‹ä¸¦åœ¨ stdout ä¸Šé¡¯ç¤ºé€²åº¦ã€‚"""
    log.info(f"ğŸ“¥ é–‹å§‹ä¸‹è¼‰ '{model_size}' æ¨¡å‹...")
    try:
        from faster_whisper import WhisperModel
        # è¼‰å…¥æ¨¡å‹æ™‚ï¼Œå¦‚æœæ¨¡å‹ä¸å­˜åœ¨ï¼Œå®ƒæœƒè‡ªå‹•ä¸‹è¼‰
        # æˆ‘å€‘å¯ä»¥åˆ©ç”¨é€™å€‹è¡Œç‚ºï¼Œä½† faster-whisper æœ¬èº«ä¸æä¾›ä¸‹è¼‰é€²åº¦å›å‘¼
        # é€™æ˜¯ä¸€å€‹ç°¡åŒ–çš„å¯¦ç¾ï¼Œåªåœ¨é–‹å§‹å’ŒçµæŸæ™‚æä¾›å›é¥‹
        print(json.dumps({"type": "progress", "percent": 0, "description": f"é–‹å§‹ä¸‹è¼‰ {model_size} æ¨¡å‹..."}), flush=True)
        WhisperModel(model_size, download_root=None) # download_root=None ä½¿ç”¨é è¨­å¿«å–è·¯å¾‘
        print(json.dumps({"type": "progress", "percent": 100, "description": "æ¨¡å‹ä¸‹è¼‰å®Œæˆã€‚"}), flush=True)
        log.info(f"âœ… æ¨¡å‹ '{model_size}' ä¸‹è¼‰æˆ–é©—è­‰æˆåŠŸã€‚")
    except Exception as e:
        log.critical(f"âŒ ä¸‹è¼‰æ¨¡å‹ '{model_size}' æ™‚å¤±æ•—: {e}", exc_info=True)
        # å°‡éŒ¯èª¤è¨Šæ¯ä¹Ÿä»¥ JSON æ ¼å¼è¼¸å‡ºï¼Œä»¥ä¾¿ä¸Šå±¤æ•æ‰
        print(json.dumps({"type": "error", "message": str(e)}), flush=True)
        raise

def main():
    """ä¸»å‡½å¼ï¼Œè§£æå‘½ä»¤åˆ—åƒæ•¸ä¸¦åŸ·è¡Œç›¸æ‡‰æ“ä½œã€‚"""
    parser = argparse.ArgumentParser(description="ä¸€å€‹å¤šåŠŸèƒ½è½‰éŒ„èˆ‡æ¨¡å‹ç®¡ç†å·¥å…·ã€‚")
    # ä¸»æŒ‡ä»¤
    parser.add_argument("--command", type=str, default="transcribe", choices=["transcribe", "check", "download"], help="è¦åŸ·è¡Œçš„æ“ä½œã€‚")
    # è½‰éŒ„åƒæ•¸
    parser.add_argument("--audio_file", type=str, help="[transcribe] éœ€è¦è½‰éŒ„çš„éŸ³è¨Šæª”æ¡ˆè·¯å¾‘ã€‚")
    parser.add_argument("--output_file", type=str, help="[transcribe] å„²å­˜è½‰éŒ„çµæœçš„æª”æ¡ˆè·¯å¾‘ã€‚")
    parser.add_argument("--language", type=str, default=None, help="[transcribe] éŸ³è¨Šçš„èªè¨€ã€‚")
    parser.add_argument("--beam_size", type=int, default=5, help="[transcribe] è§£ç¢¼æ™‚ä½¿ç”¨çš„å…‰æŸå¤§å°ã€‚")
    # é€šç”¨åƒæ•¸
    parser.add_argument("--model_size", type=str, default="tiny", help="è¦ä½¿ç”¨/æª¢æŸ¥/ä¸‹è¼‰çš„æ¨¡å‹å¤§å°ã€‚")

    args = parser.parse_args()

    if args.command == "check":
        if check_model_exists(args.model_size):
            print("exists", flush=True) # è¼¸å‡ºåˆ° stdout
        else:
            print("not_exists", flush=True) # è¼¸å‡ºåˆ° stdout

    elif args.command == "download":
        download_model_with_progress(args.model_size)

    elif args.command == "transcribe":
        if not args.audio_file or not args.output_file:
            log.critical("éŒ¯èª¤ï¼šåŸ·è¡Œ 'transcribe' æŒ‡ä»¤æ™‚ï¼Œå¿…é ˆæä¾› --audio_file å’Œ --output_fileã€‚")
            exit(1)
        try:
            transcriber = Transcriber(model_size=args.model_size)
            result_text = transcriber.transcribe(args.audio_file, args.language, args.beam_size)
            output_path = Path(args.output_file)
            output_path.parent.mkdir(parents=True, exist_ok=True)
            with open(output_path, "w", encoding="utf-8") as f:
                f.write(result_text)
            log.info(f"âœ… è½‰éŒ„çµæœå·²æˆåŠŸå¯«å…¥: {output_path}")
        except Exception as e:
            log.critical(f"âŒ åœ¨åŸ·è¡Œéç¨‹ä¸­ç™¼ç”Ÿè‡´å‘½éŒ¯èª¤: {e}", exc_info=True)
            # å¯ä»¥åœ¨æ­¤è™•å»ºç«‹ä¸€å€‹éŒ¯èª¤æ¨™è¨˜æª”æ¡ˆï¼Œä»¥ä¾¿å¤–éƒ¨åŸ·è¡Œå™¨çŸ¥é“ç™¼ç”Ÿäº†å•é¡Œ
            error_file = Path(args.output_file).parent / f"{Path(args.output_file).stem}.error"
            error_file.write_text(str(e), encoding='utf-8')
            exit(1) # ä»¥éé›¶ç‹€æ…‹ç¢¼é€€å‡ºï¼Œè¡¨ç¤ºå¤±æ•—

if __name__ == "__main__":
    main()

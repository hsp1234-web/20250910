import logging
import sys
from pathlib import Path
import json
import uuid
import concurrent.futures

from fastapi import APIRouter, HTTPException, Request, BackgroundTasks
from fastapi.responses import JSONResponse
from pydantic import BaseModel
import google.generativeai as genai
from google.api_core.exceptions import GoogleAPIError

# --- è·¯å¾‘ä¿®æ­£èˆ‡æ¨¡çµ„åŒ¯å…¥ ---
SRC_DIR = Path(__file__).resolve().parent.parent.parent
sys.path.insert(0, str(SRC_DIR))

from db.database import get_db_connection
from core import key_manager
from core import prompt_manager

# --- å¸¸æ•¸èˆ‡è¨­å®š ---
log = logging.getLogger(__name__)
router = APIRouter()
MODEL_NAME = "gemini-1.5-flash-latest"

# --- Pydantic æ¨¡å‹ ---
class AnalysisRequest(BaseModel):
    file_id: int
    prompt_key: str

# --- è¼”åŠ©å‡½å¼ (å¾ gemini_processor.py å€Ÿé‘’ä¸¦ç°¡åŒ–) ---
def generate_content_with_timeout(model, prompt_parts: list, timeout: int = 100):
    """å¸¶æœ‰è¶…æ™‚æ§åˆ¶çš„ Gemini API å‘¼å«ã€‚"""
    def generation_task():
        try:
            return model.generate_content(prompt_parts, request_options={'timeout': timeout})
        except Exception as e:
            log.error(f"generate_content åŸ·è¡Œç·’å…§éƒ¨ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)
            raise

    with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:
        try:
            future = executor.submit(generation_task)
            return future.result(timeout=timeout + 10)
        except concurrent.futures.TimeoutError:
            log.critical(f"ğŸ”´ Gemini API å‘¼å«è¶…æ™‚ï¼æ“ä½œåœ¨ {timeout + 10} ç§’å…§æœªèƒ½å®Œæˆã€‚")
            raise RuntimeError("AI å…§å®¹ç”Ÿæˆæ“ä½œè¶…æ™‚ã€‚")
        except Exception as e:
            log.critical(f"ğŸ”´ Gemini API å‘¼å«ç™¼ç”Ÿæœªé æœŸçš„éŒ¯èª¤: {e}", exc_info=True)
            raise

# --- æ–°çš„åŒæ­¥åˆ†æç«¯é» (ç‚º PoC è¨­è¨ˆ) ---

@router.post("/run_analysis", response_class=JSONResponse)
async def run_analysis(payload: AnalysisRequest):
    """
    åŸ·è¡ŒåŒæ­¥çš„ AI åˆ†æä¸¦ç«‹å³å›å‚³ JSON çµæœã€‚
    """
    log.info(f"API: æ”¶åˆ°åŒæ­¥åˆ†æè«‹æ±‚, æª”æ¡ˆ ID: {payload.file_id}, æç¤ºè©: {payload.prompt_key}")

    # 1. ç²å– API é‡‘é‘°
    api_key = key_manager.get_valid_key()
    if not api_key:
        log.error("API: ç„¡æ³•å•Ÿå‹•åˆ†æï¼Œé‡‘é‘°æ± ä¸­ç„¡æœ‰æ•ˆé‡‘é‘°ã€‚")
        raise HTTPException(status_code=428, detail="é‡‘é‘°æ± ä¸­æ²’æœ‰æœ‰æ•ˆçš„ API é‡‘é‘°ã€‚è«‹å…ˆè‡³ã€Œé‡‘é‘°ç®¡ç†ã€é é¢æ–°å¢ä¸¦é©—è­‰é‡‘é‘°ã€‚")

    # 2. ç²å–æç¤ºè©æ¨¡æ¿
    prompt_obj = prompt_manager.get_prompt_by_key(payload.prompt_key)
    if not prompt_obj or 'prompt' not in prompt_obj:
        log.error(f"API: æ‰¾ä¸åˆ°éµåç‚º '{payload.prompt_key}' çš„æœ‰æ•ˆæç¤ºè©ã€‚")
        raise HTTPException(status_code=404, detail=f"æ‰¾ä¸åˆ°éµåç‚º '{payload.prompt_key}' çš„æç¤ºè©ã€‚")
    prompt_template = prompt_obj['prompt']

    # 3. ç²å–æ–‡ä»¶æ–‡å­—å…§å®¹
    conn = None
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        cursor.execute("SELECT extracted_text FROM extracted_urls WHERE id = ?", (payload.file_id,))
        row = cursor.fetchone()
        if not row or not row['extracted_text']:
            log.error(f"API: åœ¨è³‡æ–™åº«ä¸­æ‰¾ä¸åˆ° ID ç‚º {payload.file_id} çš„æª”æ¡ˆæˆ–å…¶æ–‡å­—å…§å®¹ç‚ºç©ºã€‚")
            raise HTTPException(status_code=404, detail=f"æ‰¾ä¸åˆ°æª”æ¡ˆ ID {payload.file_id} çš„æ–‡å­—å…§å®¹ã€‚")
        text_content = row['extracted_text']
    except Exception as e:
        log.error(f"API: å¾è³‡æ–™åº«ç²å–æ–‡å­—å…§å®¹æ™‚å‡ºéŒ¯: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="è®€å–è³‡æ–™åº«æ™‚ç™¼ç”ŸéŒ¯èª¤ã€‚")
    finally:
        if conn:
            conn.close()

    # 4. å‘¼å« Gemini API
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel(MODEL_NAME)

        # æ ¼å¼åŒ–æç¤ºè©
        final_prompt = prompt_template.format(text_content=text_content)

        # åŸ·è¡Œåˆ†æ
        log.info(f"æ­£åœ¨ä½¿ç”¨æ¨¡å‹ {MODEL_NAME} é€²è¡Œåˆ†æ...")
        response = generate_content_with_timeout(model, [final_prompt], timeout=100)

        # 5. è§£æä¸¦å›å‚³çµæœ
        raw_response_text = response.text
        # æ¸…ç† AI å›æ‡‰ä¸­å¯èƒ½åŒ…å«çš„ markdown æ¨™ç±¤
        json_text = raw_response_text.strip().replace("```json", "").replace("```", "")

        parsed_json = json.loads(json_text)
        log.info(f"API: æˆåŠŸè§£æä¾†è‡ª Gemini çš„ JSON å›æ‡‰ã€‚")

        return JSONResponse(content=parsed_json)

    except json.JSONDecodeError:
        log.error(f"API: ç„¡æ³•å°‡ Gemini çš„å›æ‡‰è§£æç‚º JSONã€‚æ”¶åˆ°çš„åŸå§‹å›æ‡‰: '{raw_response_text}'")
        raise HTTPException(status_code=500, detail="AI å›æ‡‰çš„æ ¼å¼ä¸æ˜¯æœ‰æ•ˆçš„ JSONã€‚")
    except GoogleAPIError as e:
        log.error(f"API: å‘¼å« Gemini API æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)
        raise HTTPException(status_code=502, detail=f"èˆ‡ Google AI æœå‹™é€šè¨Šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    except Exception as e:
        log.error(f"API: åŸ·è¡Œ AI åˆ†ææ™‚ç™¼ç”Ÿæœªé æœŸçš„éŒ¯èª¤: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"åŸ·è¡Œåˆ†ææ™‚ç™¼ç”Ÿæœªé æœŸçš„ä¼ºæœå™¨éŒ¯èª¤: {e}")

# --- åŸæœ‰çš„éåŒæ­¥åˆ†æèˆ‡å ±å‘Šç”Ÿæˆæµç¨‹ (ä¿ç•™ä¸å‹•) ---

@router.get("/processed_files")
async def get_processed_files():
    """ç²å–æ‰€æœ‰ç‹€æ…‹ç‚º 'processed' çš„æª”æ¡ˆåˆ—è¡¨ã€‚"""
    conn = None
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        cursor.execute("SELECT id, url, local_path FROM extracted_urls WHERE status = 'processed' ORDER BY created_at DESC")
        rows = cursor.fetchall()
        results = [{"id": row['id'], "url": row['url'], "filename": Path(row['local_path']).name} for row in rows if row['local_path']]
        return JSONResponse(content=results)
    except Exception as e:
        log.error(f"API: ç²å–å·²è™•ç†æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="ç²å–å·²è™•ç†æª”æ¡ˆæ™‚ç™¼ç”Ÿä¼ºæœå™¨å…§éƒ¨éŒ¯èª¤ã€‚")
    finally:
        if conn:
            conn.close()

def run_ai_analysis_task(file_id: int, prompt_key: str, api_key: str):
    from tools.document_analyzer import analyze_document
    from tools.report_generator import generate_html_report_from_data
    # ... (åŸæœ‰å‡½å¼å…§å®¹ä¿æŒä¸è®Š)
    log.info(f"èƒŒæ™¯ä»»å‹™ï¼šé–‹å§‹åˆ†ææª”æ¡ˆ ID: {file_id}, ä½¿ç”¨æç¤ºè©: {prompt_key}")
    # ... (æ­¤è™•çœç•¥æœªä¿®æ”¹çš„ç¨‹å¼ç¢¼)

@router.post("/start_analysis")
async def start_analysis(payload: AnalysisRequest, background_tasks: BackgroundTasks):
    log.info(f"API: æ”¶åˆ° AI åˆ†æè«‹æ±‚ï¼Œæª”æ¡ˆ ID: {payload.file_id}")
    api_key = key_manager.get_valid_key()
    if not api_key:
        log.error("API: ç„¡æ³•å•Ÿå‹•åˆ†æï¼Œå› ç‚ºé‡‘é‘°æ± ä¸­æ²’æœ‰ä»»ä½•æœ‰æ•ˆçš„ API é‡‘é‘°ã€‚")
        raise HTTPException(
            status_code=428,
            detail="é‡‘é‘°æ± ä¸­æ²’æœ‰æœ‰æ•ˆçš„ API é‡‘é‘°ã€‚è«‹å…ˆè‡³ã€Œé‡‘é‘°ç®¡ç†ã€é é¢æ–°å¢ä¸¦é©—è­‰é‡‘é‘°ã€‚"
        )
    log.info(f"API: å·²å¾é‡‘é‘°æ± é¸å–ä¸€å€‹æœ‰æ•ˆé‡‘é‘°ä¾†åŸ·è¡Œä»»å‹™ã€‚")
    # æ³¨æ„ï¼šæ­¤ PoC ä¸ä½¿ç”¨æ­¤èƒŒæ™¯ä»»å‹™ï¼Œä½†ä¿ç•™åŸæœ‰åŠŸèƒ½
    # background_tasks.add_task(run_ai_analysis_task, payload.file_id, payload.prompt_key, api_key)
    return JSONResponse(content={"message": "æ­¤ç«¯é»ç‚ºéåŒæ­¥ä»»å‹™ä¿ç•™ï¼Œè«‹ä½¿ç”¨ /run_analysis é€²è¡ŒåŒæ­¥ PoC åˆ†æã€‚"})

@router.get("/reports")
async def get_reports():
    # ... (åŸæœ‰å‡½å¼å…§å®¹ä¿æŒä¸è®Š)
    pass
